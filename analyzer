#!/usr/bin/env python3
'''Recurrence complexity analyzer '''
import sys
import statistics
from os import listdir, path
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import preprocessing, svm
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
import math

class RecRel:
    ''' a structure storing the final results of recurrence relation '''
    def __init__(self, a: int, coef: float, diff: float):
        self.a = a
        self.coef = coef
        self.diff = diff

class Node:
    ''' node of a parsing tree '''
    def __init__(self, d: int, a: int, val: float):
        self.d = d
        self.a = a
        self.val = val

def read_logs(filename: str):
    ''' reads traces from a file and returns calculated coeficients and diffs'''

    with open(filename) as file:
        lines = file.readlines()
        num_rec_calls = get_num_rec_calls(lines)
        queue, coefs, diffs = [], [], []
        prev  = Node(-1, 1, 0.0)
        for i, line in enumerate(lines):
            cur = get_cur_node(line)
            # find the bottom of the branch
            if (prev.d <= cur.d and len(lines) - 1 != i):
                prev = cur
                queue.append(cur)
                continue
            # calculate coefs for the current branch
            coefs, diffs = calc_coefs(queue, coefs, diffs, num_rec_calls)
            queue.append(cur)
            prev = cur
    file.close()
    return coefs, diffs, num_rec_calls

def calc_coefs(queue, coefs, diffs, num_rec_calls):
    ''' calculates coeficients and diff.'''

    # get parent node
    p_index = len(queue)-1-num_rec_calls
    if (p_index < 0):
        return coefs, diffs
    parent = queue[p_index]

    # prepare a list of coefs
    if len(coefs) == 0:
        coefs = [[] for i in range(num_rec_calls)]
        diffs = [[] for i in range(num_rec_calls)]

    for i in range(num_rec_calls-1, -1, -1):
        child = queue.pop()
        if child.val != float(0) and child.val != float(1):
            coefs[i].append(float(parent.val) / float(child.val))
            diffs[i].append(float(parent.val) - float(child.val))

    # while we backtracking we have to make sure that the level is fully 'filled'
    count = 1
    prev = parent
    for i in range(1, num_rec_calls, 1):
        index = len(queue) - 1 - i
        if index < 0:
            break
        node = queue[index]
        if prev.d == node.d:
            count += 1
        prev = node

    if count == num_rec_calls:
        calc_coefs(queue, coefs, diffs, num_rec_calls)
    return coefs, diffs

def get_cur_node(line: str):
    ''' builds and returns a Node that fed by the parsed string from traces '''

    # each line has the following format: depth;a;n. TODO: derive 'a' using a static analysis tool
    m = line.rstrip('\n').split(';')
    m = [int(m[0]), int(m[1]), m[2]]
    return Node(m[0], m[1], float(m[2]))

def get_num_rec_calls(lines: list):
    ''' returns the number of recursive calls that a function does.
    Basically, it is a number of branches each parent node has'''

    max_depth, nums = 0, 1
    prev = Node(-1, 1, 0.0)
    for i, line in enumerate(lines):
        # print(line)
        cur = get_cur_node(line)
        if cur.d < prev.d:
            return nums
        if (prev.d <= cur.d and len(lines) - 1 > i):
            if max_depth < cur.d:
                max_depth = cur.d
                nums = 1
            if prev.d == cur.d and cur.d == max_depth:
                nums += 1
        prev = cur
    return nums

def read_traces(filename):
    ''' reads traces from a file. format "size;counter"'''
    sizes = []
    counters = []
    with open(filename) as file:
        lines = file.readlines()
    for line in lines:
        size, counter = line.split(';')
        sizes.append(int(size))
        counters.append(int(counter.strip()))

    return sizes, counters

def get_regression(size, counter):

    #quadratic polynomial fit
    x = np.array(size)
    y = np.array(counter)
    z = np.polyfit(x, y, 2)
    quadratic = int(z[0])

    #linear regression
    y = np.array(counter)
    z = np.polyfit(x, y, 1)
    linear = int(z[0])

    # #logarithmic fit
    logs = [math.log(c, 2) if c is not 0  else 0 for c in counter] #arbitrary make log(0,10) = 0
    y = np.array(logs)
    z = np.polyfit(x, y, 1)
    logs = int(z[0])

    return quadratic, linear, logs

dir_name = sys.argv[1]
num_rec_calls = 0

filenames = [f for f in listdir(dir_name) if f != 'traces']
final_coefs, final_diffs = [], []
for filename in filenames:
    # print("analyzing a file:{}".format(filename))
    coefs, diffs, num_rec_calls = read_logs(dir_name + "/" + filename)
    if len(final_coefs) == 0:
        final_coefs = coefs
        final_diffs = diffs

    for i, coef in enumerate(coefs):
        final_coefs[i].extend([c for c in coef])
    for i, diff in enumerate(diffs):
        final_diffs[i].extend([d for d in diff])

x = [i for i,v in enumerate(final_coefs[0])]
rec_relations = []

for i,coefs in enumerate(final_coefs):
    data = np.array([x, coefs])
    df = pd.DataFrame(list(zip(x, coefs)), columns=['node ids', 'coefs'])

    X = np.array(df['node ids']).reshape(-1, 1)
    y = np.array(df['coefs']).reshape(-1, 1)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
    regr = LinearRegression()

    regr.fit(X_train, y_train)
    # print("intercept: ", regr.intercept_)
    # print("coef: ", regr.coef_)

    med_diff = statistics.median(final_diffs[i])
    rec_relations.append(RecRel(1, regr.intercept_[0], med_diff))


flat_list = [item for sublist in final_coefs for item in sublist]
x = [i for i,v in enumerate(flat_list)]
df = pd.DataFrame({'x': x, 'y': flat_list}, columns=['x','y'])
kmeans = KMeans(n_clusters=num_rec_calls)
kmeans.fit(df)
centroids = kmeans.cluster_centers_
central_coef = [item[1] for item in centroids]
# print("centroids ", central_coef)

#calculating non-recursive complexity
complexity = "1"
if path.exists("{}/traces".format(dir_name)):
    size, counter = read_traces("{}/traces".format(dir_name))
    quadratic, linear, logs = get_regression(size, counter)
    if quadratic >= 1:
        complexity = "n^2"
    elif linear >= 1:
        complexity = "n"
    elif logs >= 1:
        complexity = "log(n)"


print("Recurrent relation is ")
for i in range(len(final_coefs)):
    print("diff {} regr {} kmeans {} ".format(rec_relations[i].diff, rec_relations[i].coef, central_coef[i]))
    coef = rec_relations[i].coef if rec_relations[i].coef > central_coef[i] else central_coef[i]
    # there is no theory behind why 1.7 is selected. it is an observation
    # definitely the better approach is needed to define
    if coef <= float(1.6):
        res = int(round(rec_relations[i].diff))
        print(str(rec_relations[i].a) + "*T(n-" + str(res) + ") + " + complexity)
    else:
        res = int(round(coef))
        print(str(rec_relations[i].a) + "*T(n/" + str(res) + ") + " + complexity)
